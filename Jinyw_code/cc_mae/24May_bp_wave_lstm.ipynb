{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs =125 # Sample rate in Hz\n",
    "bp_standard_rate = 200\n",
    "\n",
    "def remove_worse_patient(patient_list, number_remove_list):\n",
    "    for number in number_remove_list:\n",
    "        if number in patient_list:\n",
    "            patient_list.remove(number)\n",
    "    return patient_list\n",
    "\n",
    "import numpy as np\n",
    "def straighten_ecg(ecg_signal):\n",
    "    detrended_ecg = np.subtract(ecg_signal, np.mean(ecg_signal))\n",
    "    return detrended_ecg\n",
    "    \n",
    "import numpy as np\n",
    "def normalize_sinal(ppg):\n",
    "# Assuming ppg_signal and ecg_signal are your original PPG and ECG signals\n",
    "    ppg_min = np.min(ppg)\n",
    "    ppg_max = np.max(ppg)\n",
    "    normalized_ppg = (ppg - ppg_min) / (ppg_max - ppg_min)\n",
    "    return normalized_ppg\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "def align_ppgbp(ppg_signal, bp_signal1, bp_signal2, ecg_signal, show=0): ## ppg_signal = ppg_normalized, bp_signal = bp_normalized, ecg_signal = ecg_normalized; get ppg_aligned, bp_aligned\n",
    "    try:\n",
    "        ppg_peaks, _ = find_peaks(ppg_signal, height=0.5)  # Adjust the height threshold as needed\n",
    "        bp_peaks, _ = find_peaks(bp_signal1, height=0.1)\n",
    "        ecg_peaks, _ = find_peaks(ecg_signal, height=0.65)\n",
    "        #print(f'ppg peaks: {len(ppg_peaks)} {ppg_peaks}')\n",
    "        #print(f'ecg peaks: {len(ecg_peaks)} {ecg_peaks}')\n",
    "\n",
    "        first_ecg_peak = ecg_peaks[0]\n",
    "        #print(f'first ecg peak: {first_ecg_peak}')\n",
    "        indices_ppg = np.argwhere(ppg_peaks[:10] > first_ecg_peak)\n",
    "        first_ppg_peak = ppg_peaks[int(indices_ppg[0])]\n",
    "        #print(f'first ppg peak: {first_ppg_peak}')\n",
    "        indices_bp = np.argwhere(bp_peaks[:10] > first_ecg_peak)\n",
    "        if len(indices_bp) > 0:\n",
    "            first_bp_peak = bp_peaks[int(indices_bp[0])]\n",
    "            #print(f'first bp peak: {first_bp_peak}')\n",
    "            ppg_bp_peaks_subtraction = abs(bp_peaks[int(indices_bp[0]):int(indices_bp[0])+5] - ppg_peaks[int(indices_ppg[0]):int(indices_ppg[0])+5])\n",
    "            #print(ppg_bp_peaks_subtraction)\n",
    "            distance_ppgbp = np.bincount(ppg_bp_peaks_subtraction).argmax()\n",
    "            #print(distance_ppgbp)\n",
    "            #print(bp_peaks[int(indices_bp[0]):int(indices_bp[0])+20] - ppg_peaks[int(indices_ppg[0]):int(indices_ppg[0])+20])\n",
    "            #print(f'distance:{distance_ppgbp}')\n",
    "            if first_bp_peak > first_ppg_peak:\n",
    "                bp_aligned = bp_signal1[distance_ppgbp:]\n",
    "                bp_ori_aligned = bp_signal2[distance_ppgbp:]\n",
    "                ppg_aligned = ppg_signal\n",
    "            elif first_bp_peak < first_ppg_peak:\n",
    "                bp_aligned = bp_signal1\n",
    "                bp_ori_aligned = bp_signal2\n",
    "                ppg_aligned = ppg_signal[distance_ppgbp:]\n",
    "            else:\n",
    "                bp_aligned = bp_signal1\n",
    "                bp_ori_aligned = bp_signal2\n",
    "                ppg_aligned = ppg_signal\n",
    "            #print(f'ppg len: {len(ppg_aligned)}')\n",
    "            #print(f'bp len: {len(bp_aligned)}')\n",
    "            min_len = min(len(bp_aligned), len(ppg_aligned))\n",
    "            ppg_aligned = ppg_aligned[:min_len]\n",
    "            bp_aligned = bp_aligned[:min_len]\n",
    "            bp_ori_aligned = bp_ori_aligned[:min_len]\n",
    "            ecg_aligned = ecg_signal[:min_len]\n",
    "\n",
    "            if show == 1:\n",
    "                plt.figure(figsize=(30, 6))\n",
    "                plt.plot(ppg_signal, label='PPG')\n",
    "                plt.plot(bp_signal1, label='BP')\n",
    "                plt.plot(ecg_signal, label='ECG')\n",
    "                plt.scatter(ppg_peaks, ppg_signal[ppg_peaks], color='c', marker='o', label='Aligned PPG Peaks')\n",
    "                plt.scatter(bp_peaks, bp_signal1[bp_peaks], color='orange', marker='o', label='Aligned BP Peaks')\n",
    "                plt.scatter(ecg_peaks, ecg_signal[ecg_peaks], color='green', marker='o', label='Aligned BP Peaks')\n",
    "                plt.xlabel('Time')\n",
    "                plt.ylabel('Amplitude')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "                plt.figure(figsize=(30, 6))\n",
    "                plt.plot(ppg_aligned, label='PPG')\n",
    "                plt.plot(bp_aligned, label='BP')\n",
    "                plt.plot(ecg_aligned, label='ECG')\n",
    "                plt.xlabel('Time')\n",
    "                plt.ylabel('Amplitude')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            return ppg_aligned, bp_aligned, bp_ori_aligned, ecg_aligned\n",
    "        else:\n",
    "            raise IndexError\n",
    "    except IndexError:\n",
    "        raise IndexError\n",
    "\n",
    "\n",
    "# Reshape\n",
    "def reshape_data(X, y, time_steps):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps), :])\n",
    "        ys.append(y[i+time_steps-1])\n",
    "    return np.array(Xs), np.array(ys) \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    loss = mean_squared_error(y_true*250, y_pred*250)\n",
    "    return loss\n",
    "\n",
    "def bpwave_lstm_model(X_train, y_train, time_steps):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, return_sequences=True, input_shape=(time_steps, X_train.shape[-1])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=100))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss=custom_loss)\n",
    "    model.fit(X_train, y_train, epochs=200, verbose=1)\n",
    "    return model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def show_one(signal1):\n",
    "    fig = plt.figure(figsize=(30,6))\n",
    "    plt.plot(signal1)\n",
    "    return plt.show()\n",
    "def show_two(signal1, signal2):\n",
    "    fig = plt.figure(figsize=(30,6))\n",
    "    plt.plot(signal1, label='1')\n",
    "    plt.plot(signal2, label='2')\n",
    "    plt.legend()\n",
    "    return plt.show()\n",
    "def show_three(signal1, signal2, signal3):\n",
    "    fig = plt.figure(figsize=(30,6))\n",
    "    plt.plot(signal1, label='1')\n",
    "    plt.plot(signal2, label='2')\n",
    "    plt.plot(signal3, label='3')\n",
    "    plt.legend()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the 1000 patients data\n",
    "import scipy.io\n",
    "data1 = scipy.io.loadmat('/Users/jinyanwei/Desktop/BP_Model/Data/Cuffless_BP_Estimation/part_1.mat')\n",
    "for patient in range(1):\n",
    "    patient_data = data1['p'][0, patient][0, :]\n",
    "    if len(patient_data) > 4000:\n",
    "        #print(patient)\n",
    "        patient_data = data1['p'][0, patient][:, :4000]\n",
    "        ppg_ori = patient_data[0]\n",
    "        bp_ori = patient_data[1]\n",
    "        ecg_ori = patient_data[2]\n",
    "        ecg_detrened = straighten_ecg(ecg_ori)\n",
    "        ppg_normalized = normalize_sinal(ppg_ori)\n",
    "        bp_standarded = bp_ori / bp_standard_rate\n",
    "        ecg_normalized = normalize_sinal(ecg_detrened)\n",
    "        ppg_segmented, bp_segmented, bp_ori_segmented, ecg_segmented = align_ppgbp(ppg_signal = ppg_normalized, bp_signal1 = bp_standarded, bp_signal2 = bp_ori, ecg_signal = ecg_normalized, show=0)\n",
    "patients_list = [1,3,5,16,23,24,27,28,29,30,32,33,34,35,36,37,38,39,40,41,42,44,45,46,63,67,70,71,73,76,78,79,80,81,82,103,104,120,128,129,151,156,158,161,170,172,173,183,186,187,192,193,194,196,197,198,199,200,201,203,206,207,213,214,218,220,221,227,229,236,243,248,253,254,284,286,295,298,299,303,304,305,317,336,338,343,344,346,348,350,351,355,356,357,368,369,371,372,403,412]\n",
    "#print(len(patients_list))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 100patients\n",
    "train_ppgs = []\n",
    "train_ecgs = []\n",
    "train_bps = []\n",
    "train_bp_oris = []\n",
    "test_ppgs = []\n",
    "test_ecgs = []\n",
    "test_bps = []\n",
    "test_bp_oris = []\n",
    "for patient in patients_list[:-20]:\n",
    "    patient_data = data1['p'][0,patient][:,:4000]\n",
    "    ppg_ori = patient_data[0]\n",
    "    bp_ori = patient_data[1]\n",
    "    ecg_ori = patient_data[2]\n",
    "    ecg_detrened = straighten_ecg(ecg_ori)\n",
    "    ppg_normalized = normalize_sinal(ppg_ori)\n",
    "    bp_standarded = bp_ori / bp_standard_rate\n",
    "    ecg_normalized = normalize_sinal(ecg_detrened)\n",
    "    ppg_aligned, bp_aligned, bp_ori_aligned, ecg_aligned = align_ppgbp(ppg_signal = ppg_normalized, bp_signal1 = bp_standarded, bp_signal2 = bp_ori, ecg_signal = ecg_normalized, show=0)\n",
    "    train_ppgs.append(ppg_aligned)\n",
    "    train_ecgs.append(ecg_aligned)\n",
    "    train_bps.append(bp_aligned)\n",
    "    train_bp_oris.append(bp_ori_aligned)\n",
    "for patient in patients_list[-20:]:\n",
    "    patient_data = data1['p'][0,patient][:,:4000]\n",
    "    ppg_ori = patient_data[0]\n",
    "    bp_ori = patient_data[1]\n",
    "    ecg_ori = patient_data[2]\n",
    "    ecg_detrened = straighten_ecg(ecg_ori)\n",
    "    ppg_normalized = normalize_sinal(ppg_ori)\n",
    "    bp_standarded = bp_ori / bp_standard_rate\n",
    "    ecg_normalized = normalize_sinal(ecg_detrened)\n",
    "    ppg_aligned, bp_aligned, bp_ori_aligned, ecg_aligned = align_ppgbp(ppg_signal = ppg_normalized, bp_signal1 = bp_standarded, bp_signal2 = bp_ori, ecg_signal = ecg_normalized, show=0)\n",
    "    train_ppgs.append(ppg_aligned[:int(0.2*len(ppg_aligned))])\n",
    "    train_ecgs.append(ecg_aligned[:int(0.2*len(ecg_aligned))])\n",
    "    train_bps.append(bp_aligned[:int(0.2*len(bp_aligned))]) \n",
    "    train_bp_oris.append(bp_ori_aligned[:int(0.2*len(bp_ori_aligned))]) \n",
    "    test_ppgs.append(ppg_aligned[int(0.2*len(ppg_aligned)):])\n",
    "    test_ecgs.append(ecg_aligned[int(0.2*len(ecg_aligned)):])\n",
    "    test_bps.append(bp_aligned[int(0.2*len(bp_aligned)):])  \n",
    "    test_bp_oris.append(bp_ori_aligned[int(0.2*len(bp_ori_aligned)):])  \n",
    "train_ppg = np.concatenate(train_ppgs, axis=0)\n",
    "train_ecg = np.concatenate(train_ecgs, axis=0)\n",
    "train_bp = np.concatenate(train_bps, axis=0)\n",
    "train_bp_ori = np.concatenate(train_bp_oris, axis=0)\n",
    "train_feature = np.column_stack((train_ppg, train_ecg)) \n",
    "\n",
    "### Model\n",
    "time_steps = 15\n",
    "X_train, y_train = reshape_data(train_feature,train_bp,time_steps)\n",
    "bpwave_lstm_model = bpwave_lstm_model(X_train, y_train, time_steps)\n",
    "bpwave_lstm_model.save('bpwave_lstm_model100.h5')\n",
    "\n",
    "### CC\n",
    "#from keras.models import load_model\n",
    "#bpwave_lstm_model = load_model('lstm_model.h5')\n",
    "import pandas as pd\n",
    "pred_bps = []\n",
    "cc_df = pd.DataFrame(columns=(('refbp_estbp_cc', 'refbp_ppg_cc', 'refbp_ecg_cc', 'refbp_estbp_md', 'refbp_estbp_sd')))\n",
    "\n",
    "for i in range(len(test_bps)):\n",
    "    test_ppg = test_ppgs[i]\n",
    "    test_ecg = test_ecgs[i]\n",
    "    test_feature = np.column_stack((test_ppg, test_ecg))\n",
    "    X_test, y_test = reshape_data(test_feature, test_bps[i], time_steps)\n",
    "    y_pred = bpwave_lstm_model.predict(X_test)\n",
    "    y_pred = y_pred.flatten()\n",
    "    test_ppg = test_ppg[time_steps-1:-1]\n",
    "    test_ecg = test_ecg[time_steps-1:-1]\n",
    "    #print(y_test.shape, y_pred.shape, test_ppg.shape, test_ecg.shape)\n",
    "    pred_bps.append(y_pred)\n",
    "    md = np.mean(y_pred*250-y_test*250)\n",
    "    std = np.std(y_pred*250-y_test*250)\n",
    "    cc_refbp_estbp = np.abs(np.corrcoef(y_test, y_pred)[0, 1])\n",
    "    #print(cc_refbp_estbp)\n",
    "    cc_refbp_ppg = np.abs(np.corrcoef(y_test, test_ppg)[0, 1])\n",
    "    cc_refbp_ecg = np.abs(np.corrcoef(y_test, test_ecg)[0, 1])\n",
    "    cc_df.loc[len(cc_df)] = [cc_refbp_estbp, cc_refbp_ppg, cc_refbp_ecg, md, std]\n",
    "\n",
    "cc_df.loc[len(cc_df)] = [np.mean(cc_df['refbp_estbp_cc']), np.mean(cc_df['refbp_ppg_cc']), np.mean(cc_df['refbp_ecg_cc']), np.mean(cc_df['refbp_estbp_md']), np.mean(cc_df['refbp_estbp_sd'])]\n",
    "cc_df = cc_df.rename(index={len(cc_df)-1: 'ave'})\n",
    "cc_df.to_csv('100bpppgecgcc20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adjust time_steps\n",
    "time_steps = 15\n",
    "feature0 = np.column_stack((train_ppgs[0], train_ecgs[0])) \n",
    "bp0 = train_bps[0]\n",
    "X_train0, y_train0 = reshape_data(feature0[:int(0.8*len(feature0))],bp0[:int(0.8*len(bp0))],time_steps)\n",
    "model0 = bpwave_lstm_model(X_train0,y_train0,time_steps)\n",
    "\n",
    "X_test0, y_test0 = reshape_data(feature0[int(0.8*len(feature0)):],bp0[int(0.8*len(bp0)):],time_steps)\n",
    "y_pred0 = model0.predict(X_test0)\n",
    "mae = np.mean(np.abs(y_pred0*bp_standard_rate - y_test0*bp_standard_rate))\n",
    "rmse = np.sqrt(np.mean((y_pred0*bp_standard_rate-y_test0*bp_standard_rate)**2))\n",
    "print(f'MAE: {mae}, RMSE: {rmse}')\n",
    "show_two(y_test0*bp_standard_rate, y_pred0*bp_standard_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmax_length = max(len(part1patients),len(part2patients),len(part3patients),len(part4patients))\\npart1patients += [np.nan]*(max_length - len(part1patients))\\npart2patients += [np.nan]*(max_length - len(part2patients))\\npart3patients += [np.nan]*(max_length - len(part3patients))\\npart4patients += [np.nan]*(max_length - len(part4patients))\\nall4patients = pd.DataFrame({'part1': part1patients,'part2': part2patients,'part3': part3patients,'part4': part4patients})\\nall4patients.replace(np.nan, inplace=True)\\nall4patients = all4patients.astype(int)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read 3000 patients data\n",
    "import sys\n",
    "sys.path.append('/Users/jinyanwei/Desktop/BP_Model/Jinyw_code/')\n",
    "from read_data import open_data\n",
    "datab1 = open_data('/Users/jinyanwei/Desktop/BP_Model/Data/UCI/Part_1.mat')\n",
    "datab2 = open_data('/Users/jinyanwei/Desktop/BP_Model/Data/UCI/Part_2.mat')\n",
    "datab3 = open_data('/Users/jinyanwei/Desktop/BP_Model/Data/UCI/Part_3.mat')\n",
    "datab4 = open_data('/Users/jinyanwei/Desktop/BP_Model/Data/UCI/Part_4.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all4patients_text = pd.read_csv('/Users/jinyanwei/Desktop/BP_Model/Data/UCI/lly_features.csv')\n",
    "part1patients = [int(string.split('_')[-1]) for string in all4patients_text['part1'].dropna()]\n",
    "part2patients = [int(string.split('_')[-1]) for string in all4patients_text['part2'].dropna()]\n",
    "part3patients = [int(string.split('_')[-1]) for string in all4patients_text['part3'].dropna()]\n",
    "part4patients = [int(string.split('_')[-1]) for string in all4patients_text['part4'].dropna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1remove = [2335,41,82,1749,744,2040,5,1159,42,1776,553,219,1174,1]\n",
    "part1patients = remove_worse_patient(part1patients, part1remove)\n",
    "part2remove = []\n",
    "part2patients = remove_worse_patient(part2patients,part2remove)\n",
    "part3remove = []\n",
    "part3patients = remove_worse_patient(part3patients,part3remove)\n",
    "part4remove = []\n",
    "part4patients = remove_worse_patient(part4patients,part4remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 660patients\n",
    "train_ppgs = []\n",
    "train_ecgs = []\n",
    "train_bps = []\n",
    "train_bp_oris = []\n",
    "test_ppgs = []\n",
    "test_ecgs = []\n",
    "test_bps = []\n",
    "test_bp_oris = []\n",
    "for patient in part1patients[:-20]:\n",
    "    if len(datab1[patient])>4000:\n",
    "        print(f'part1{patient}')\n",
    "        patient_data = datab1[patient][:,:4000]\n",
    "        ppg_ori = patient_data[:,0]\n",
    "        bp_ori = patient_data[:,1]\n",
    "        ecg_ori = patient_data[:,2]\n",
    "        ecg_detrened = straighten_ecg(ecg_ori)\n",
    "        ppg_normalized = normalize_sinal(ppg_ori)\n",
    "        bp_standarded = bp_ori / bp_standard_rate\n",
    "        ecg_normalized = normalize_sinal(ecg_detrened)\n",
    "        ppg_aligned, bp_aligned, bp_ori_aligned, ecg_aligned = align_ppgbp(ppg_signal = ppg_normalized, bp_signal1 = bp_standarded, bp_signal2 = bp_ori, ecg_signal = ecg_normalized, show=0)\n",
    "        train_ppgs.append(ppg_aligned)\n",
    "        train_ecgs.append(ecg_aligned)\n",
    "        train_bps.append(bp_aligned)\n",
    "        train_bp_oris.append(bp_ori_aligned)  \n",
    "for patient in part2patients[:-20]:\n",
    "    if len(datab2[patient])>4000:\n",
    "        patient_data = datab2[patient][:,:4000]\n",
    "        ppg_ori = patient_data[:,0]\n",
    "        bp_ori = patient_data[:,1]\n",
    "        ecg_ori = patient_data[:,2]\n",
    "        ecg_detrened = straighten_ecg(ecg_ori)\n",
    "        ppg_normalized = normalize_sinal(ppg_ori)\n",
    "        bp_standarded = bp_ori / bp_standard_rate\n",
    "        ecg_normalized = normalize_sinal(ecg_detrened)\n",
    "        ppg_aligned, bp_aligned, bp_ori_aligned, ecg_aligned = align_ppgbp(ppg_signal = ppg_normalized, bp_signal1 = bp_standarded, bp_signal2 = bp_ori, ecg_signal = ecg_normalized, show=0)\n",
    "        train_ppgs.append(ppg_aligned)\n",
    "        train_ecgs.append(ecg_aligned)\n",
    "        train_bps.append(bp_aligned)\n",
    "        train_bp_oris.append(bp_ori_aligned)\n",
    "for patient in part3patients[:-20]:\n",
    "    if len(datab3[patient])>4000:\n",
    "        patient_data = datab3[patient][:,:4000]\n",
    "        ppg_ori = patient_data[:,0]\n",
    "        bp_ori = patient_data[:,1]\n",
    "        ecg_ori = patient_data[:,2]\n",
    "        ecg_detrened = straighten_ecg(ecg_ori)\n",
    "        ppg_normalized = normalize_sinal(ppg_ori)\n",
    "        bp_standarded = bp_ori / bp_standard_rate\n",
    "        ecg_normalized = normalize_sinal(ecg_detrened)\n",
    "        ppg_aligned, bp_aligned, bp_ori_aligned, ecg_aligned = align_ppgbp(ppg_signal = ppg_normalized, bp_signal1 = bp_standarded, bp_signal2 = bp_ori, ecg_signal = ecg_normalized, show=0)\n",
    "        train_ppgs.append(ppg_aligned)\n",
    "        train_ecgs.append(ecg_aligned)\n",
    "        train_bps.append(bp_aligned)\n",
    "        train_bp_oris.append(bp_ori_aligned)\n",
    "for patient in part4patients[:-20]:\n",
    "    if len(datab4[patient])>4000:\n",
    "        patient_data = datab4[patient][:,:4000]\n",
    "        ppg_ori = patient_data[:,0]\n",
    "        bp_ori = patient_data[:,1]\n",
    "        ecg_ori = patient_data[:,2]\n",
    "        ecg_detrened = straighten_ecg(ecg_ori)\n",
    "        ppg_normalized = normalize_sinal(ppg_ori)\n",
    "        bp_standarded = bp_ori / bp_standard_rate\n",
    "        ecg_normalized = normalize_sinal(ecg_detrened)\n",
    "        ppg_aligned, bp_aligned, bp_ori_aligned, ecg_aligned = align_ppgbp(ppg_signal = ppg_normalized, bp_signal1 = bp_standarded, bp_signal2 = bp_ori, ecg_signal = ecg_normalized, show=0)\n",
    "        train_ppgs.append(ppg_aligned)\n",
    "        train_ecgs.append(ecg_aligned)\n",
    "        train_bps.append(bp_aligned)\n",
    "        train_bp_oris.append(bp_ori_aligned) \n",
    "for patient in part1patients[-20:]:\n",
    "    if len(datab1[patient])>4000:\n",
    "        patient_data = datab1[patient][:,:4000]\n",
    "        ppg_ori = patient_data[:,0]\n",
    "        bp_ori = patient_data[:,1]\n",
    "        ecg_ori = patient_data[:,2]\n",
    "        ecg_detrened = straighten_ecg(ecg_ori)\n",
    "        ppg_normalized = normalize_sinal(ppg_ori)\n",
    "        bp_standarded = bp_ori / bp_standard_rate\n",
    "        ecg_normalized = normalize_sinal(ecg_detrened)\n",
    "        ppg_aligned, bp_aligned, bp_ori_aligned, ecg_aligned = align_ppgbp(ppg_signal = ppg_normalized, bp_signal1 = bp_standarded, bp_signal2 = bp_ori, ecg_signal = ecg_normalized, show=0)\n",
    "        train_ppgs.append(ppg_aligned[:int(0.2*len(ppg_aligned))])\n",
    "        train_ecgs.append(ecg_aligned[:int(0.2*len(ecg_aligned))])\n",
    "        train_bps.append(bp_aligned[:int(0.2*len(bp_aligned))]) \n",
    "        train_bp_oris.append(bp_ori_aligned[:int(0.2*len(bp_ori_aligned))]) \n",
    "        test_ppgs.append(ppg_aligned[int(0.2*len(ppg_aligned)):])\n",
    "        test_ecgs.append(ecg_aligned[int(0.2*len(ecg_aligned)):])\n",
    "        test_bps.append(bp_aligned[int(0.2*len(bp_aligned)):])  \n",
    "        test_bp_oris.append(bp_ori_aligned[int(0.2*len(bp_ori_aligned)):])  \n",
    "for patient in part2patients[-20:]:\n",
    "    if len(datab2[patient])>4000:\n",
    "        patient_data = datab2[patient][:,:4000]\n",
    "        ppg_ori = patient_data[:,0]\n",
    "        bp_ori = patient_data[:,1]\n",
    "        ecg_ori = patient_data[:,2]\n",
    "        ecg_detrened = straighten_ecg(ecg_ori)\n",
    "        ppg_normalized = normalize_sinal(ppg_ori)\n",
    "        bp_standarded = bp_ori / bp_standard_rate\n",
    "        ecg_normalized = normalize_sinal(ecg_detrened)\n",
    "        ppg_aligned, bp_aligned, bp_ori_aligned, ecg_aligned = align_ppgbp(ppg_signal = ppg_normalized, bp_signal1 = bp_standarded, bp_signal2 = bp_ori, ecg_signal = ecg_normalized, show=0)\n",
    "        train_ppgs.append(ppg_aligned[:int(0.2*len(ppg_aligned))])\n",
    "        train_ecgs.append(ecg_aligned[:int(0.2*len(ecg_aligned))])\n",
    "        train_bps.append(bp_aligned[:int(0.2*len(bp_aligned))]) \n",
    "        train_bp_oris.append(bp_ori_aligned[:int(0.2*len(bp_ori_aligned))]) \n",
    "        test_ppgs.append(ppg_aligned[int(0.2*len(ppg_aligned)):])\n",
    "        test_ecgs.append(ecg_aligned[int(0.2*len(ecg_aligned)):])\n",
    "        test_bps.append(bp_aligned[int(0.2*len(bp_aligned)):])  \n",
    "        test_bp_oris.append(bp_ori_aligned[int(0.2*len(bp_ori_aligned)):])  \n",
    "for patient in part3patients[-20:]:\n",
    "    if len(datab3[patient])>4000:\n",
    "        patient_data = datab3[patient][:,:4000]\n",
    "        ppg_ori = patient_data[:,0]\n",
    "        bp_ori = patient_data[:,1]\n",
    "        ecg_ori = patient_data[:,2]\n",
    "        ecg_detrened = straighten_ecg(ecg_ori)\n",
    "        ppg_normalized = normalize_sinal(ppg_ori)\n",
    "        bp_standarded = bp_ori / bp_standard_rate\n",
    "        ecg_normalized = normalize_sinal(ecg_detrened)\n",
    "        ppg_aligned, bp_aligned, bp_ori_aligned, ecg_aligned = align_ppgbp(ppg_signal = ppg_normalized, bp_signal1 = bp_standarded, bp_signal2 = bp_ori, ecg_signal = ecg_normalized, show=0)\n",
    "        train_ppgs.append(ppg_aligned[:int(0.2*len(ppg_aligned))])\n",
    "        train_ecgs.append(ecg_aligned[:int(0.2*len(ecg_aligned))])\n",
    "        train_bps.append(bp_aligned[:int(0.2*len(bp_aligned))]) \n",
    "        train_bp_oris.append(bp_ori_aligned[:int(0.2*len(bp_ori_aligned))]) \n",
    "        test_ppgs.append(ppg_aligned[int(0.2*len(ppg_aligned)):])\n",
    "        test_ecgs.append(ecg_aligned[int(0.2*len(ecg_aligned)):])\n",
    "        test_bps.append(bp_aligned[int(0.2*len(bp_aligned)):])  \n",
    "        test_bp_oris.append(bp_ori_aligned[int(0.2*len(bp_ori_aligned)):])  \n",
    "for patient in part4patients[-20:]:\n",
    "    if len(datab4[patient])>4000:\n",
    "        patient_data = datab4[patient][:,:4000]\n",
    "        ppg_ori = patient_data[:,0]\n",
    "        bp_ori = patient_data[:,1]\n",
    "        ecg_ori = patient_data[:,2]\n",
    "        ecg_detrened = straighten_ecg(ecg_ori)\n",
    "        ppg_normalized = normalize_sinal(ppg_ori)\n",
    "        bp_standarded = bp_ori / bp_standard_rate\n",
    "        ecg_normalized = normalize_sinal(ecg_detrened)\n",
    "        ppg_aligned, bp_aligned, bp_ori_aligned, ecg_aligned = align_ppgbp(ppg_signal = ppg_normalized, bp_signal1 = bp_standarded, bp_signal2 = bp_ori, ecg_signal = ecg_normalized, show=0)\n",
    "        train_ppgs.append(ppg_aligned[:int(0.2*len(ppg_aligned))])\n",
    "        train_ecgs.append(ecg_aligned[:int(0.2*len(ecg_aligned))])\n",
    "        train_bps.append(bp_aligned[:int(0.2*len(bp_aligned))]) \n",
    "        train_bp_oris.append(bp_ori_aligned[:int(0.2*len(bp_ori_aligned))]) \n",
    "        test_ppgs.append(ppg_aligned[int(0.2*len(ppg_aligned)):])\n",
    "        test_ecgs.append(ecg_aligned[int(0.2*len(ecg_aligned)):])\n",
    "        test_bps.append(bp_aligned[int(0.2*len(bp_aligned)):])  \n",
    "        test_bp_oris.append(bp_ori_aligned[int(0.2*len(bp_ori_aligned)):])  \n",
    "train_ppg = np.concatenate(train_ppgs, axis=0)\n",
    "train_ecg = np.concatenate(train_ecgs, axis=0)\n",
    "train_bp = np.concatenate(train_bps, axis=0)\n",
    "train_bp_ori = np.concatenate(train_bp_oris, axis=0)\n",
    "train_feature = np.column_stack((train_ppg, train_ecg)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model\n",
    "time_steps = 15\n",
    "X_train, y_train = reshape_data(train_feature,train_bp,time_steps)\n",
    "bpwave_lstm_model = bpwave_lstm_model(X_train, y_train, time_steps)\n",
    "bpwave_lstm_model.save('bpwave_lstm_model660.h5')\n",
    "\n",
    "### CC\n",
    "#from keras.models import load_model\n",
    "#bpwave_lstm_model = load_model('lstm_model.h5')\n",
    "import pandas as pd\n",
    "pred_bps = []\n",
    "cc_df = pd.DataFrame(columns=(('refbp_estbp_cc', 'refbp_ppg_cc', 'refbp_ecg_cc', 'refbp_estbp_md', 'refbp_estbp_sd')))\n",
    "\n",
    "for i in range(len(test_bps)):\n",
    "    test_ppg = test_ppgs[i]\n",
    "    test_ecg = test_ecgs[i]\n",
    "    test_feature = np.column_stack((test_ppg, test_ecg))\n",
    "    X_test, y_test = reshape_data(test_feature, test_bps[i], time_steps)\n",
    "    y_pred = bpwave_lstm_model.predict(X_test)\n",
    "    y_pred = y_pred.flatten()\n",
    "    test_ppg = test_ppg[time_steps-1:-1]\n",
    "    test_ecg = test_ecg[time_steps-1:-1]\n",
    "    #print(y_test.shape, y_pred.shape, test_ppg.shape, test_ecg.shape)\n",
    "    pred_bps.append(y_pred)\n",
    "    md = np.mean(y_pred*bp_standard_rate-y_test*bp_standard_rate)\n",
    "    std = np.std(y_pred*bp_standard_rate-y_test*bp_standard_rate)\n",
    "    cc_refbp_estbp = np.abs(np.corrcoef(y_test, y_pred)[0, 1])\n",
    "    #print(cc_refbp_estbp)\n",
    "    cc_refbp_ppg = np.abs(np.corrcoef(y_test, test_ppg)[0, 1])\n",
    "    cc_refbp_ecg = np.abs(np.corrcoef(y_test, test_ecg)[0, 1])\n",
    "    cc_df.loc[len(cc_df)] = [cc_refbp_estbp, cc_refbp_ppg, cc_refbp_ecg, md, std]\n",
    "\n",
    "cc_df.loc[len(cc_df)] = [np.mean(cc_df['refbp_estbp_cc']), np.mean(cc_df['refbp_ppg_cc']), np.mean(cc_df['refbp_ecg_cc']), np.mean(cc_df['refbp_estbp_md']), np.mean(cc_df['refbp_estbp_sd'])]\n",
    "cc_df = cc_df.rename(index={len(cc_df)-1: 'ave'})\n",
    "cc_df.to_csv('660bpppgecgcc80.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
