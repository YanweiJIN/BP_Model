{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import scipy.signal as signal\n",
    "import scipy.io as sio\n",
    "import scipy.stats\n",
    "from scipy.fft import fft\n",
    "import neurokit2 as nk\n",
    "import heartpy as hp\n",
    "import nolds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import nolds\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/jinyanwei/Desktop/BP_Model/Jinyw_code/')\n",
    "from read_data import open_data\n",
    "from filter_and_clean_data import clean_data\n",
    "from segment_and_features import features_data\n",
    "from random_forest import run_random_forest\n",
    "\n",
    "all_data = open_data('/Users/jinyanwei/Desktop/BP_Model/Data/UCI/Part_1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectData:\n",
    "    def __init__(self, data_array, data_begin=0, data_end=-1):\n",
    "        self.array = data_array[data_begin:data_end]\n",
    "\n",
    "    def signal_data(self): # PPG, BP, ECG\n",
    "        return self.array[:,0], self.array[:,1], self.array[:,2]\n",
    "\n",
    "    def show_data(self, show_begin=0, show_end=-1):\n",
    "        fig, ax = plt.subplots(figsize=(30,6))\n",
    "        ax.plot(self.array[show_begin:show_end])\n",
    "        plt.show(fig)\n",
    "        \n",
    "def find_first_peak(signal):\n",
    "    # Calculate the first order difference\n",
    "    diff_signal = np.diff(signal)\n",
    "    middle_signal = (np.max(signal) + np.min(signal))/2\n",
    "    # Find the index of the first positive-to-negative transition\n",
    "    for i in range(len(diff_signal) - 1):\n",
    "        if (diff_signal[i] > 0 and diff_signal[i + 1] < 0) and (signal[i] > middle_signal):\n",
    "            return i + 1\n",
    "    return -1\n",
    "\n",
    "def align_first_peaks(signal1, signal2):\n",
    "    # Find the index of the first peak in each signal\n",
    "    first_peak_index1 = find_first_peak(signal1)\n",
    "    first_peak_index2 = find_first_peak(signal2)\n",
    "    index_diff = first_peak_index1 - first_peak_index2\n",
    "    if index_diff < 0:\n",
    "        aligned_signal1 = signal1\n",
    "        aligned_signal2 = signal2[abs(index_diff):]\n",
    "    elif index_diff > 0:\n",
    "        aligned_signal1 = signal1[index_diff:]\n",
    "        aligned_signal2 = signal2\n",
    "    else:\n",
    "        aligned_signal1 = signal1\n",
    "        aligned_signal2 = signal2\n",
    "\n",
    "    return aligned_signal1, aligned_signal2\n",
    "\n",
    "def cleaned_data(ppg_aligned, bp_aligned, ecg_standardized):\n",
    "    sampling_rate = 125\n",
    "    ecgpeaks, _ = signal.find_peaks(ecg_standardized, distance=sampling_rate//2.5)\n",
    "    sum_beats = 0\n",
    "    times_recorder = []\n",
    "    cleaned_df = pd.DataFrame()\n",
    "    for R_peak_number in range(len(ecgpeaks)-1):\n",
    "        sum_beats += 1\n",
    "        if ecg_standardized[ecgpeaks[R_peak_number]] > 0.2 and ecg_standardized[ecgpeaks[R_peak_number + 1]]>0.2:\n",
    "            onebeat_bppeak, _ = signal.find_peaks(bp_aligned[ecgpeaks[R_peak_number]:ecgpeaks[R_peak_number + 1]], distance = sampling_rate//2.5)\n",
    "            if len(onebeat_bppeak) == 1 : # make sure only one BP signal for one beat \n",
    "                saved_df = pd.DataFrame([ppg_aligned[ecgpeaks[R_peak_number]:ecgpeaks[R_peak_number + 1]], bp_aligned[ecgpeaks[R_peak_number]:ecgpeaks[R_peak_number + 1]], ecg_standardized[ecgpeaks[R_peak_number]:ecgpeaks[R_peak_number + 1]]]).T\n",
    "                cleaned_df = pd.concat([cleaned_df, saved_df])\n",
    "                times_recorder.append(sum_beats)\n",
    "    cleaned_df.columns=('PPG', 'BP', 'ECG')\n",
    "    return cleaned_df\n",
    "\n",
    "from numpy.fft import fft\n",
    "\n",
    "def extract_ppg_features(signal):\n",
    "\n",
    "    '''\n",
    "    #### Chaotic features\n",
    "\n",
    "    lyap_r = nolds.lyap_r(signal)\n",
    "    hurst_exp = nolds.hurst_rs(signal)\n",
    "    corr_dim = nolds.corr_dim(signal, 1)\n",
    "\n",
    "    '''\n",
    "\n",
    "    #### Time domain features\n",
    "    mean = np.mean(signal)\n",
    "    std_dev = np.std(signal)\n",
    "    skewness = scipy.stats.skew(signal)\n",
    "    kurtosis = scipy.stats.kurtosis(signal)\n",
    "\n",
    "    #### Frequency domain features\n",
    "    fft_values = fft(signal)\n",
    "    power_spectrum = np.abs(fft_values)**2\n",
    "    total_power = np.sum(power_spectrum)\n",
    "    low_freq_power = np.sum(power_spectrum[:len(power_spectrum)//2]) / total_power\n",
    "    high_freq_power = np.sum(power_spectrum[len(power_spectrum)//2:]) / total_power\n",
    "\n",
    "    ppg_features = {\n",
    "        #'lyap_r': lyap_r,\n",
    "        #'hurst_exp': hurst_exp,\n",
    "        #'corr_dim': corr_dim,\n",
    "        'ppg_mean': mean,\n",
    "        'ppg_std_dev': std_dev,\n",
    "        'ppg_skewness': skewness,\n",
    "        'ppg_kurtosis': kurtosis,\n",
    "        'ppg_low_freq_power': low_freq_power,\n",
    "        'ppg_high_freq_power': high_freq_power\n",
    "    }\n",
    "\n",
    "    return ppg_features\n",
    "\n",
    "def extract_ecg_features(signal):\n",
    "\n",
    "    '''\n",
    "    #### Chaotic features\n",
    "\n",
    "    lyap_r = nolds.lyap_r(signal)\n",
    "    hurst_exp = nolds.hurst_rs(signal)\n",
    "    corr_dim = nolds.corr_dim(signal, 1)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Time domain features\n",
    "    mean = np.mean(signal)\n",
    "    std_dev = np.std(signal)\n",
    "    skewness = scipy.stats.skew(signal)\n",
    "    kurtosis = scipy.stats.kurtosis(signal)\n",
    "\n",
    "    # Frequency domain features\n",
    "    fft_values = fft(signal)\n",
    "    power_spectrum = np.abs(fft_values)**2\n",
    "    total_power = np.sum(power_spectrum)\n",
    "    low_freq_power = np.sum(power_spectrum[:len(power_spectrum)//2]) / total_power\n",
    "    high_freq_power = np.sum(power_spectrum[len(power_spectrum)//2:]) / total_power\n",
    "\n",
    "    ecg_features = {\n",
    "        #'lyap_r': lyap_r,\n",
    "        #'hurst_exp': hurst_exp,\n",
    "        #'corr_dim': corr_dim,\n",
    "        'ecg_mean': mean,\n",
    "        'ecg_std_dev': std_dev,\n",
    "        'ecg_skewness': skewness,\n",
    "        'ecg_kurtosis': kurtosis,\n",
    "        'ecg_low_freq_power': low_freq_power,\n",
    "        'ecg_high_freq_power': high_freq_power\n",
    "    }\n",
    "\n",
    "    return ecg_features\n",
    "\n",
    "def get_bp_features(df):\n",
    "    sampling_rate = 125\n",
    "    ecgpeaks, _ = signal.find_peaks(df['ECG'], distance=sampling_rate//2.5)\n",
    "    ppg_segments, ecg_segments, SBPlist, DBPlist, bplist = [], [], [], [], []\n",
    "    for peak_number in range(1, len(ecgpeaks)-2):    # data will be more stable from the second R-peak\n",
    "        ppg_segments.append(df['PPG'][ecgpeaks[peak_number]:ecgpeaks[peak_number + 1]].values)\n",
    "        ecg_segments.append(df['ECG'][ecgpeaks[peak_number]:ecgpeaks[peak_number + 1]].values)\n",
    "        bplist = df['BP'][ecgpeaks[peak_number]:ecgpeaks[peak_number+1]]\n",
    "        SBPlist.append(max(bplist))\n",
    "        DBPlist.append(min(bplist))\n",
    "\n",
    "    ppg_feature_list = [extract_ppg_features(ppg_segment) for ppg_segment in ppg_segments]\n",
    "    ecg_feature_list = [extract_ecg_features(ecg_segment) for ecg_segment in ecg_segments]\n",
    "    features_df = pd.concat([pd.DataFrame(ppg_feature_list), pd.DataFrame(ecg_feature_list)], axis=1)\n",
    "\n",
    "    return np.array(SBPlist), np.array(DBPlist), features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "def create_sequences(X, y, time_steps=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X.iloc[i:(i + time_steps)])\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)  \n",
    "\n",
    "def bp_lstm_model(train_features_df, train_bp):\n",
    "    time_steps = 10\n",
    "    X_train, y_train_ori = create_sequences(train_features_df, pd.DataFrame(train_bp), time_steps)\n",
    "    y_train = np.around(((y_train_ori - y_train_ori.min()) / (y_train_ori.max() - y_train_ori.min())), decimals=4)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, return_sequences=True, input_shape=(time_steps, 12)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=100))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=200, verbose=1)\n",
    "    return model\n",
    "\n",
    "def get_bp_point(test_features_df, test_bp, model):\n",
    "    time_steps = 10\n",
    "    X_test, y_test = create_sequences(test_features_df, pd.DataFrame(test_bp), time_steps)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_recover = (y_pred * (y_test.max() - y_test.min())) + y_test.min()\n",
    "    return y_test, y_pred_recover\n",
    "\n",
    "def bp_wave_lstm_modle(df_train):\n",
    "    time_steps = 10\n",
    "    X_train, y_train_ori = create_sequences(df_train[['PPG', 'ECG']], df_train['BP'], time_steps)\n",
    "    y_train = np.around(((y_train_ori - y_train_ori.min()) / (y_train_ori.max() - y_train_ori.min())), decimals=4)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(time_steps, 2)))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=1)\n",
    "    return model\n",
    "\n",
    "def get_bp_wave(df_test, model):\n",
    "    time_steps = 10\n",
    "    X_test, y_test = create_sequences(df_test[['PPG', 'ECG']], df_test['BP'], time_steps)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_recover = (y_pred * (y_test.max() - y_test.min())) + y_test.min()\n",
    "    return y_test, y_pred_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_list(patient_num):\n",
    "    pat = 0\n",
    "    pat_list = []\n",
    "\n",
    "    while len(pat_list) < (patient_num*1.5):\n",
    "        datapat = all_data[pat]\n",
    "        if len(datapat) > 45000:\n",
    "            pat_list.append(pat)\n",
    "        pat += 1\n",
    "    print(pat_list)\n",
    "\n",
    "    patient_list = []\n",
    "    data_ready = pd.DataFrame()\n",
    "    for i in pat_list:\n",
    "        patient_array = SelectData(all_data[i])\n",
    "        ppg, bp, ecg = patient_array.signal_data()\n",
    "        ppg_filtered = nk.signal_filter(ppg, lowcut=0.5, highcut=50, method='butterworth', order=2, sampling_rate=125)\n",
    "        ppg_standardized = np.around(((ppg_filtered - ppg_filtered.min()) / (ppg_filtered.max() - ppg_filtered.min())), decimals=4)\n",
    "        ecg_filtered = nk.signal_filter(ecg, lowcut=0.5, highcut=50, method='butterworth', order=2, sampling_rate=125)\n",
    "        ecg_standardized = np.around(((ecg_filtered - ecg_filtered.min()) / (ecg_filtered.max() - ecg_filtered.min())), decimals=4)\n",
    "        ppg_aligned, bp_aligned = align_first_peaks(ppg_standardized, bp)\n",
    "        cleaned_df = cleaned_data(ppg_aligned, bp_aligned, ecg_standardized)\n",
    "        if len(cleaned_df) > 45000:\n",
    "            patient_list.append(i)\n",
    "            data_ready = pd.concat([data_ready, cleaned_df[:22500]])\n",
    "    data_ready.to_csv(f'wave_train_data{patient_list[0]}_{patient_list[-1]}.csv')\n",
    "    train_sbp, train_dbp, train_features_df = get_bp_features(data_ready)\n",
    "    train_features_df.to_csv(f'fearutes_train_data{patient_list[0]}_{patient_list[-1]}.csv')\n",
    "    print(len(patient_list))\n",
    "    return patient_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_one_patient(patient_number):  \n",
    "    patient_array = SelectData(all_data[patient_number])\n",
    "    ppg, bp, ecg = patient_array.signal_data()\n",
    "    ppg_filtered = nk.signal_filter(ppg, lowcut=0.5, highcut=50, method='butterworth', order=2, sampling_rate=125)\n",
    "    ppg_standardized = np.around(((ppg_filtered - ppg_filtered.min()) / (ppg_filtered.max() - ppg_filtered.min())), decimals=4)\n",
    "    ecg_filtered = nk.signal_filter(ecg, lowcut=0.5, highcut=50, method='butterworth', order=2, sampling_rate=125)\n",
    "    ecg_standardized = np.around(((ecg_filtered - ecg_filtered.min()) / (ecg_filtered.max() - ecg_filtered.min())), decimals=4)\n",
    "    ppg_aligned, bp_aligned = align_first_peaks(ppg_standardized, bp)\n",
    "    cleaned_df = cleaned_data(ppg_aligned, bp_aligned, ecg_standardized)\n",
    "    ori_cleaned_df = cleaned_data(ppg_standardized, bp, ecg_standardized)\n",
    "    train_sbp, train_dbp, train_features_df = get_bp_features(cleaned_df[:22500])\n",
    "    sbp_lstm_model = bp_lstm_model(train_features_df, train_sbp)\n",
    "    dbp_lstm_model = bp_lstm_model(train_features_df, train_dbp)\n",
    "    bp_wave_lstm_model = bp_wave_lstm_modle(cleaned_df[:22500])\n",
    "\n",
    "    cc_wave_list = []\n",
    "    mae_lstm_list = []\n",
    "    sampling_rate = 125\n",
    "    time_steps = 10\n",
    "    test_sbp, test_dbp, test_features_df = get_bp_features(cleaned_df[22500:26500])\n",
    "    ref_sbp_lstm, est_sbp_lstm = get_bp_point(test_features_df, test_sbp, sbp_lstm_model)\n",
    "    ref_dbp_lstm, est_dbp_lstm = get_bp_point(test_features_df, test_dbp, dbp_lstm_model)\n",
    "    ref_sbp_lstm = np.squeeze(ref_sbp_lstm)\n",
    "    est_sbp_lstm = np.squeeze(est_sbp_lstm)\n",
    "    ref_dbp_lstm = np.squeeze(ref_dbp_lstm)\n",
    "    est_dbp_lstm = np.squeeze(est_dbp_lstm)\n",
    "    SelectData(np.array([ref_sbp_lstm, est_sbp_lstm]).T).show_data()\n",
    "    SelectData(np.array([ref_dbp_lstm, est_dbp_lstm]).T).show_data()\n",
    "    ref_bp_wave, est_bp_wave = get_bp_wave(cleaned_df[22500:26500], bp_wave_lstm_model)\n",
    "    est_bp_wave = np.squeeze(est_bp_wave)\n",
    "    ref_bp_aligned, est_bp_aligned = align_first_peaks(ref_bp_wave, np.squeeze(est_bp_wave))\n",
    "    ppg_wave = np.squeeze(np.array(cleaned_df[22500+time_steps:22500+time_steps+len(ref_bp_wave)]['PPG']))\n",
    "    ori_ppg_wave = np.squeeze(np.array(ori_cleaned_df[22500+time_steps:(22500+time_steps+len(est_bp_wave))]['PPG']))\n",
    "    min_len_est = min(len(ref_bp_aligned), len(est_bp_aligned))\n",
    "    ref_bp_wave_a, ppg_wave_a = align_first_peaks(ref_bp_wave, ppg_wave)\n",
    "    min_len_ppg = min(len(ref_bp_wave_a), len(ppg_wave_a))\n",
    "\n",
    "    correlation_matrix_1 = np.corrcoef(ref_bp_wave, est_bp_wave)\n",
    "    correlation_coefficient_1 = correlation_matrix_1[0, 1]\n",
    "    correlation_matrix_2 = np.corrcoef(ref_bp_wave_a[:min_len_ppg], ppg_wave_a[:min_len_ppg])\n",
    "    correlation_coefficient_2 = correlation_matrix_2[0, 1]\n",
    "    correlation_matrix_3 = np.corrcoef(ref_bp_wave[:min_len_est], est_bp_aligned[:min_len_est])\n",
    "    correlation_coefficient_3 = correlation_matrix_3[0, 1]\n",
    "    correlation_matrix_4 = np.corrcoef(ref_bp_wave, ori_ppg_wave)\n",
    "    correlation_coefficient_4 = correlation_matrix_4[0, 1]\n",
    "    cc_wave_list += [correlation_coefficient_1, correlation_coefficient_2, correlation_coefficient_3, correlation_coefficient_4]\n",
    "\n",
    "    mae_bp1 = np.mean(np.abs(ref_sbp_lstm - est_sbp_lstm))\n",
    "    mae_bp2 = np.mean(np.abs(ref_dbp_lstm - est_dbp_lstm))\n",
    "    mae_bp3 = np.mean(np.abs(ref_bp_wave - est_bp_wave))\n",
    "    mae_lstm_list += [mae_bp1, mae_bp2, mae_bp3]\n",
    "\n",
    "    SelectData(np.array([ref_sbp_lstm, est_sbp_lstm]).T).show_data()\n",
    "    SelectData(np.array([ref_dbp_lstm, est_dbp_lstm]).T).show_data()\n",
    "    SelectData(np.array([ref_bp_wave, est_bp_wave]).T).show_data()\n",
    "    SelectData(np.array([ref_bp_wave, est_bp_aligned]).T).show_data()\n",
    "    SelectData(ppg_wave).show_data()\n",
    "    SelectData(ref_bp_wave).show_data()\n",
    "    SelectData(ori_ppg_wave).show_data()\n",
    "    SelectData(ppg_wave_a[:min_len_ppg]).show_data()\n",
    "    SelectData(ref_bp_wave_a[:min_len_ppg]).show_data()\n",
    "    print(cc_wave_list)\n",
    "    print(mae_lstm_list)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3*（10， 30， 60）ppg \n",
    "def for_bp_ppg_cc_mae(patient_list):\n",
    "    cc_wave_df10 = pd.DataFrame(columns=(('refbp_estbp1', 'refbp_ppg1', 'refbp_aligened_estbp1', 'refbp_orippg1','refbp_estbp2', 'refbp_ppg2', 'refbp_aligened_estbp2', 'refbp_orippg2', 'refbp_estbp3', 'refbp_ppg3', 'refbp_aligened_estbp3', 'refbp_orippg3')))\n",
    "    mae_lstm_df10 = pd.DataFrame(columns=(('refsbp_estsbp1', 'refdbp_estdbp1', 'refbpwave_estbpwave1', 'refsbp_estsbp2', 'refdbp_estdbp2', 'refbpwave_estbpwave2', 'refsbp_estsbp3', 'refdbp_estdbp3', 'refbpwave_estbpwave3')))\n",
    "    cc_wave_df30 = pd.DataFrame(columns=(('refbp_estbp1', 'refbp_ppg1', 'refbp_aligened_estbp1', 'refbp_orippg1','refbp_estbp2', 'refbp_ppg2', 'refbp_aligened_estbp2', 'refbp_orippg2', 'refbp_estbp3', 'refbp_ppg3', 'refbp_aligened_estbp3', 'refbp_orippg3')))\n",
    "    mae_lstm_df30 = pd.DataFrame(columns=(('refsbp_estsbp1', 'refdbp_estdbp1', 'refbpwave_estbpwave1', 'refsbp_estsbp2', 'refdbp_estdbp2', 'refbpwave_estbpwave2', 'refsbp_estsbp3', 'refdbp_estdbp3', 'refbpwave_estbpwave3')))\n",
    "    cc_wave_df60 = pd.DataFrame(columns=(('refbp_estbp1', 'refbp_ppg1', 'refbp_aligened_estbp1', 'refbp_orippg1','refbp_estbp2', 'refbp_ppg2', 'refbp_aligened_estbp2', 'refbp_orippg2', 'refbp_estbp3', 'refbp_ppg3', 'refbp_aligened_estbp3', 'refbp_orippg3')))\n",
    "    mae_lstm_df60 = pd.DataFrame(columns=(('refsbp_estsbp1', 'refdbp_estdbp1', 'refbpwave_estbpwave1', 'refsbp_estsbp2', 'refdbp_estdbp2', 'refbpwave_estbpwave2', 'refsbp_estsbp3', 'refdbp_estdbp3', 'refbpwave_estbpwave3')))\n",
    "    for patient in patient_list:\n",
    "        patient_array = SelectData(all_data[patient])\n",
    "        ppg, bp, ecg = patient_array.signal_data()\n",
    "        ppg_filtered = nk.signal_filter(ppg, lowcut=0.5, highcut=50, method='butterworth', order=2, sampling_rate=125)\n",
    "        ppg_standardized = np.around(((ppg_filtered - ppg_filtered.min()) / (ppg_filtered.max() - ppg_filtered.min())), decimals=4)\n",
    "        ecg_filtered = nk.signal_filter(ecg, lowcut=0.5, highcut=50, method='butterworth', order=2, sampling_rate=125)\n",
    "        ecg_standardized = np.around(((ecg_filtered - ecg_filtered.min()) / (ecg_filtered.max() - ecg_filtered.min())), decimals=4)\n",
    "        ppg_aligned, bp_aligned = align_first_peaks(ppg_standardized, bp)\n",
    "        cleaned_df = cleaned_data(ppg_aligned, bp_aligned, ecg_standardized)\n",
    "        ori_cleaned_df = cleaned_data(ppg_standardized, bp, ecg_standardized)\n",
    "        train_sbp, train_dbp, train_features_df = get_bp_features(cleaned_df[:22500])\n",
    "        sbp_lstm_model = bp_lstm_model(train_features_df, train_sbp)\n",
    "        dbp_lstm_model = bp_lstm_model(train_features_df, train_dbp)\n",
    "        cc_wave_list10, mae_lstm_list10 = [], []\n",
    "        cc_wave_list30, mae_lstm_list30 = [], []\n",
    "        cc_wave_list60, mae_lstm_list60 = [], []\n",
    "        bp_wave_lstm_model = bp_wave_lstm_modle(cleaned_df[:22500])\n",
    "        sampling_rate = 125\n",
    "        time_steps = 10\n",
    "\n",
    "        for i in range(3):\n",
    "            test_sbp, test_dbp, test_features_df = get_bp_features(cleaned_df[(22500+(60*sampling_rate)*i):(22500+(60*sampling_rate)*(i+1))])\n",
    "            ref_sbp_lstm, est_sbp_lstm = get_bp_point(test_features_df, test_sbp, sbp_lstm_model)\n",
    "            ref_dbp_lstm, est_dbp_lstm = get_bp_point(test_features_df, test_dbp, dbp_lstm_model)\n",
    "            ref_sbp_lstm = np.squeeze(ref_sbp_lstm)\n",
    "            est_sbp_lstm = np.squeeze(est_sbp_lstm)\n",
    "            ref_dbp_lstm = np.squeeze(ref_dbp_lstm)\n",
    "            est_dbp_lstm = np.squeeze(est_dbp_lstm)\n",
    "            ref_bp_wave, est_bp_wave = get_bp_wave(cleaned_df[(22500+(60*sampling_rate)*i):(22500+(60*sampling_rate)*(i+1))], bp_wave_lstm_model)\n",
    "            est_bp_wave = np.squeeze(est_bp_wave)\n",
    "            ref_bp_aligned, est_bp_aligned = align_first_peaks(ref_bp_wave, np.squeeze(est_bp_wave))\n",
    "            ref_bp_aligned, est_bp_aligned = align_first_peaks(ref_bp_aligned, np.squeeze(est_bp_aligned))\n",
    "            min_len_est = min(len(ref_bp_aligned), len(est_bp_aligned))\n",
    "            ref_bp_aligned = ref_bp_aligned[:min_len_est]\n",
    "            est_bp_aligned = est_bp_aligned[:min_len_est]\n",
    "            ppg_wave = np.squeeze(np.array(cleaned_df[22500+time_steps:22500+time_steps+len(ref_bp_wave)]['PPG']))\n",
    "            ori_ppg_wave = np.squeeze(np.array(ori_cleaned_df[22500+time_steps:(22500+time_steps+len(ref_bp_wave))]['PPG']))\n",
    "            ref_bp_wave_a, ppg_wave_a = align_first_peaks(ref_bp_wave, ppg_wave)\n",
    "            ref_bp_wave_a = ref_bp_wave_a[:min_len_ppg]\n",
    "            ppg_wave_a = ppg_wave_a[:min_len_ppg]\n",
    "            min_len_ppg = min(len(ref_bp_wave_a), len(ppg_wave_a))\n",
    "\n",
    "            once_time = 10\n",
    "            ref_bp_wave10 = ref_bp_wave[:int((once_time/60)*len(ref_bp_wave))]\n",
    "            est_bp_wave10 = est_bp_wave[:int((once_time/60)*len(est_bp_wave))]\n",
    "            ref_bp_wave_a10 = ref_bp_wave_a[:int((once_time/60)*len(ref_bp_wave_a))]\n",
    "            ppg_wave_a10 = ppg_wave_a[:int((once_time/60)*len(ppg_wave_a))]\n",
    "            ref_bp_aligned10 = ref_bp_aligned[:int((once_time/60)*len(ref_bp_aligned))]\n",
    "            est_bp_aligned10 = est_bp_aligned[:int((once_time/60)*len(est_bp_aligned))]\n",
    "            ori_ppg_wave10 = ori_ppg_wave[:int((once_time/60*len(ori_ppg_wave)))]\n",
    "\n",
    "            correlation_matrix_1 = np.corrcoef(ref_bp_wave10, est_bp_wave10)\n",
    "            correlation_coefficient_1 = correlation_matrix_1[0, 1]\n",
    "            correlation_matrix_2 = np.corrcoef(ref_bp_wave_a10, ppg_wave_a10)\n",
    "            correlation_coefficient_2 = correlation_matrix_2[0, 1]\n",
    "            correlation_matrix_3 = np.corrcoef(ref_bp_aligned10, est_bp_aligned10)\n",
    "            correlation_coefficient_3 = correlation_matrix_3[0, 1]\n",
    "            correlation_matrix_4 = np.corrcoef(ref_bp_wave10, ori_ppg_wave10)\n",
    "            correlation_coefficient_4 = correlation_matrix_4[0, 1]           \n",
    "\n",
    "            ref_sbp_lstm10 = ref_sbp_lstm[:int((once_time/60)*len(ref_sbp_lstm))]\n",
    "            est_sbp_lstm10 = est_sbp_lstm[:int((once_time/60)*len(est_sbp_lstm))]\n",
    "            ref_dbp_lstm10 = ref_dbp_lstm[:int((once_time/60)*len(ref_sbp_lstm))]\n",
    "            est_dbp_lstm10 = est_dbp_lstm[:int((once_time/60)*len(est_dbp_lstm))]\n",
    "            mae_bp1 = np.mean(np.abs(ref_sbp_lstm10 - est_sbp_lstm10))\n",
    "            mae_bp2 = np.mean(np.abs(ref_dbp_lstm10 - est_dbp_lstm10))\n",
    "            mae_bp3 = np.mean(np.abs(ref_bp_wave10 - est_bp_wave10))\n",
    "\n",
    "            cc_wave_list10 += [correlation_coefficient_1, correlation_coefficient_2, correlation_coefficient_3, correlation_coefficient_4]\n",
    "            mae_lstm_list10 += [mae_bp1, mae_bp2, mae_bp3] \n",
    "\n",
    "            once_time = 30\n",
    "            ref_bp_wave30 = ref_bp_wave[:int((once_time/60)*len(ref_bp_wave))]\n",
    "            est_bp_wave30 = est_bp_wave[:int((once_time/60)*len(est_bp_wave))]\n",
    "            ref_bp_wave_a30 = ref_bp_wave_a[:int((once_time/60)*len(ref_bp_wave_a))]\n",
    "            ppg_wave_a30 = ppg_wave_a[:int((once_time/60)*len(ppg_wave_a))]\n",
    "            ref_bp_aligned30 = ref_bp_aligned[:int((once_time/60)*len(ref_bp_aligned))]\n",
    "            est_bp_aligned30 = est_bp_aligned[:int((once_time/60)*len(est_bp_aligned))]\n",
    "            ori_ppg_wave30 = ori_ppg_wave[:int((once_time/60*len(ori_ppg_wave)))]\n",
    "\n",
    "            correlation_matrix_1 = np.corrcoef(ref_bp_wave30, est_bp_wave30)\n",
    "            correlation_coefficient_1 = correlation_matrix_1[0, 1]\n",
    "            correlation_matrix_2 = np.corrcoef(ref_bp_wave_a30, ppg_wave_a30)\n",
    "            correlation_coefficient_2 = correlation_matrix_2[0, 1]\n",
    "            correlation_matrix_3 = np.corrcoef(ref_bp_aligned30, est_bp_aligned30)\n",
    "            correlation_coefficient_3 = correlation_matrix_3[0, 1]\n",
    "            correlation_matrix_4 = np.corrcoef(ref_bp_wave30, ori_ppg_wave30)\n",
    "            correlation_coefficient_4 = correlation_matrix_4[0, 1]           \n",
    "\n",
    "            ref_sbp_lstm30 = ref_sbp_lstm[:int((once_time/60)*len(ref_sbp_lstm))]\n",
    "            est_sbp_lstm30 = est_sbp_lstm[:int((once_time/60)*len(est_sbp_lstm))]\n",
    "            ref_dbp_lstm30 = ref_dbp_lstm[:int((once_time/60)*len(ref_sbp_lstm))]\n",
    "            est_dbp_lstm30 = est_dbp_lstm[:int((once_time/60)*len(est_dbp_lstm))]\n",
    "            mae_bp1 = np.mean(np.abs(ref_sbp_lstm30 - est_sbp_lstm30))\n",
    "            mae_bp2 = np.mean(np.abs(ref_dbp_lstm30 - est_dbp_lstm30))\n",
    "            mae_bp3 = np.mean(np.abs(ref_bp_wave30 - est_bp_wave30))\n",
    "            cc_wave_list30 += [correlation_coefficient_1, correlation_coefficient_2, correlation_coefficient_3, correlation_coefficient_4]\n",
    "            mae_lstm_list30 += [mae_bp1, mae_bp2, mae_bp3] \n",
    "\n",
    "            once_time = 60\n",
    "            ref_bp_wave60 = ref_bp_wave[:int((once_time/60)*len(ref_bp_wave))]\n",
    "            est_bp_wave60 = est_bp_wave[:int((once_time/60)*len(est_bp_wave))]\n",
    "            ref_bp_wave_a60 = ref_bp_wave_a[:int((once_time/60)*len(ref_bp_wave_a))]\n",
    "            ppg_wave_a60 = ppg_wave_a[:int((once_time/60)*len(ppg_wave_a))]\n",
    "            ref_bp_aligned60 = ref_bp_aligned[:int((once_time/60)*len(ref_bp_aligned))]\n",
    "            est_bp_aligned60 = est_bp_aligned[:int((once_time/60)*len(est_bp_aligned))]\n",
    "            ori_ppg_wave60 = ori_ppg_wave[:int((once_time/60*len(ori_ppg_wave)))]\n",
    "\n",
    "            correlation_matrix_1 = np.corrcoef(ref_bp_wave60, est_bp_wave60)\n",
    "            correlation_coefficient_1 = correlation_matrix_1[0, 1]\n",
    "            correlation_matrix_2 = np.corrcoef(ref_bp_wave_a60, ppg_wave_a60)\n",
    "            correlation_coefficient_2 = correlation_matrix_2[0, 1]\n",
    "            correlation_matrix_3 = np.corrcoef(ref_bp_aligned60, est_bp_aligned60)\n",
    "            correlation_coefficient_3 = correlation_matrix_3[0, 1]\n",
    "            correlation_matrix_4 = np.corrcoef(ref_bp_wave60, ori_ppg_wave60)\n",
    "            correlation_coefficient_4 = correlation_matrix_4[0, 1]           \n",
    "\n",
    "            ref_sbp_lstm60 = ref_sbp_lstm[:int((once_time/60)*len(ref_sbp_lstm))]\n",
    "            est_sbp_lstm60 = est_sbp_lstm[:int((once_time/60)*len(est_sbp_lstm))]\n",
    "            ref_dbp_lstm60 = ref_dbp_lstm[:int((once_time/60)*len(ref_sbp_lstm))]\n",
    "            est_dbp_lstm60 = est_dbp_lstm[:int((once_time/60)*len(est_dbp_lstm))]\n",
    "            mae_bp1 = np.mean(np.abs(ref_sbp_lstm60 - est_sbp_lstm60))\n",
    "            mae_bp2 = np.mean(np.abs(ref_dbp_lstm60 - est_dbp_lstm60))\n",
    "            mae_bp3 = np.mean(np.abs(ref_bp_wave60 - est_bp_wave60))\n",
    "            cc_wave_list60 += [correlation_coefficient_1, correlation_coefficient_2, correlation_coefficient_3, correlation_coefficient_4]\n",
    "            mae_lstm_list60 += [mae_bp1, mae_bp2, mae_bp3] \n",
    "\n",
    "        cc_wave_df10.loc[len(cc_wave_df10)] = cc_wave_list10\n",
    "        mae_lstm_df10.loc[len(mae_lstm_df10)] =mae_lstm_list10\n",
    "        cc_wave_df30.loc[len(cc_wave_df30)] = cc_wave_list30\n",
    "        mae_lstm_df30.loc[len(mae_lstm_df30)] =mae_lstm_list30\n",
    "        cc_wave_df60.loc[len(cc_wave_df60)] = cc_wave_list60\n",
    "        mae_lstm_df60.loc[len(mae_lstm_df60)] =mae_lstm_list60\n",
    "        display(cc_wave_df10)\n",
    "        display(mae_lstm_df10)\n",
    "        display(cc_wave_df30)\n",
    "        display(mae_lstm_df30)\n",
    "        display(cc_wave_df60)\n",
    "        display(mae_lstm_df60)\n",
    "        SelectData(np.array([ref_sbp_lstm, est_sbp_lstm]).T).show_data()\n",
    "        SelectData(np.array([ref_dbp_lstm, est_dbp_lstm]).T).show_data()\n",
    "        SelectData(np.array([ref_bp_wave, est_bp_wave]).T).show_data()\n",
    "        SelectData(np.array([ref_bp_aligned, est_bp_aligned]).T).show_data()\n",
    "        SelectData(ppg_wave_a[:min_len_ppg]).show_data()\n",
    "        SelectData(ref_bp_wave_a[:min_len_ppg]).show_data()\n",
    "    cc_wave_df10.to_csv(f'cc_wave10_{len(patient_list)}.csv')\n",
    "    mae_lstm_df10.to_csv(f'mae_bp10_{len(patient_list)}.csv')\n",
    "    cc_wave_df30.to_csv(f'cc_wave30_{len(patient_list)}.csv')\n",
    "    mae_lstm_df30.to_csv(f'mae_bp30_{len(patient_list)}.csv')\n",
    "    cc_wave_df60.to_csv(f'cc_wave60_{len(patient_list)}.csv')\n",
    "    mae_lstm_df60.to_csv(f'mae_bp60_{len(patient_list)}.csv')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_list = get_patient_list(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1* 30 (wave, ppg, ecg) cc\n",
    "## 10min/patient\n",
    "def cc_waveppgecg(patient_list):\n",
    "    wave_ppg_ecg_df = pd.DataFrame(columns=(('refbp_estbp_cc', 'refbp_ppg_cc', 'refbp_ecg_cc', 'refbp_estbp_md', 'refbp_ppg_md', 'refbp_ecg_md', 'refbp_estbp_sd', 'refbp_ppg_sd', 'refbp_ecg_sd')))\n",
    "    for patient in patient_list:\n",
    "        patient_array = SelectData(all_data[patient])\n",
    "        ppg, bp, ecg = patient_array.signal_data()\n",
    "        ppg_filtered = nk.signal_filter(ppg, lowcut=0.5, highcut=50, method='butterworth', order=2, sampling_rate=125)\n",
    "        ppg_standardized = np.around(((ppg_filtered - ppg_filtered.min()) / (ppg_filtered.max() - ppg_filtered.min())), decimals=4)\n",
    "        ecg_filtered = nk.signal_filter(ecg, lowcut=0.5, highcut=50, method='butterworth', order=2, sampling_rate=125)\n",
    "        ecg_standardized = np.around(((ecg_filtered - ecg_filtered.min()) / (ecg_filtered.max() - ecg_filtered.min())), decimals=4)\n",
    "        ppg_aligned, bp_aligned = align_first_peaks(ppg_standardized, bp)\n",
    "        cleaned_df = cleaned_data(ppg_aligned, bp_aligned, ecg_standardized)\n",
    "        bp_wave_lstm_model = bp_wave_lstm_modle(cleaned_df[:22500])\n",
    "        sampling_rate = 125\n",
    "        once_time = 30\n",
    "        time_steps = 10\n",
    "        ref_bp_wave, est_bp_wave = get_bp_wave(cleaned_df[22500:(22500+30*sampling_rate)], bp_wave_lstm_model)\n",
    "        est_bp_wave = np.squeeze(est_bp_wave)\n",
    "        ref_bp_aligned, est_bp_aligned = align_first_peaks(ref_bp_wave, np.squeeze(est_bp_wave))\n",
    "        ref_bp_aligned, est_bp_aligned = align_first_peaks(ref_bp_aligned, np.squeeze(est_bp_aligned))\n",
    "        min_len_est = min(len(ref_bp_aligned), len(est_bp_aligned))\n",
    "        ref_bp_aligned = ref_bp_aligned[:min_len_est]\n",
    "        est_bp_aligned = est_bp_aligned[:min_len_est]\n",
    "        ppg_wave = np.squeeze(np.array(cleaned_df[22500+time_steps:(22500+time_steps+len(ref_bp_wave))]['PPG']))\n",
    "        ref_bp_wave_a, ppg_wave_a = align_first_peaks(ref_bp_wave, ppg_wave)\n",
    "        min_len_ppg = min(len(ref_bp_wave_a), len(ppg_wave_a))\n",
    "        ref_bp_wave_a = ref_bp_wave_a[:min_len_ppg]\n",
    "        ppg_wave_a = ppg_wave_a[:min_len_ppg]\n",
    "        ecg_wave = np.squeeze(np.array(cleaned_df[22500+time_steps:(22500+time_steps+len(ref_bp_wave))]['ECG']))\n",
    "\n",
    "        correlation_matrix_1 = np.corrcoef(ref_bp_wave, est_bp_wave)\n",
    "        correlation_coefficient_1 = correlation_matrix_1[0, 1]\n",
    "        correlation_matrix_2 = np.corrcoef(ref_bp_wave_a, ppg_wave_a)\n",
    "        correlation_coefficient_2 = correlation_matrix_2[0, 1]\n",
    "        correlation_matrix_3 = np.corrcoef(ref_bp_wave, ecg_wave)\n",
    "        correlation_coefficient_3 = correlation_matrix_3[0, 1]     \n",
    "        cc_list = [correlation_coefficient_1, correlation_coefficient_2, correlation_coefficient_3]\n",
    "        md1 = np.mean(ref_bp_wave - est_bp_wave)\n",
    "        md2 = np.mean(ref_bp_wave_a - ppg_wave_a)\n",
    "        md3 = np.mean(ref_bp_wave - ecg_wave)\n",
    "        md_list = [md1, md2, md3]\n",
    "        sd1 = np.std(ref_bp_wave - est_bp_wave)\n",
    "        sd2 = np.std(ref_bp_wave_a - ppg_wave_a)\n",
    "        sd3 = np.std(ref_bp_wave - ecg_wave)\n",
    "        sd_list = [sd1, sd2, sd3]\n",
    "        wave_ppg_ecg_list = cc_list + md_list + sd_list\n",
    "        wave_ppg_ecg_df.loc[len(wave_ppg_ecg_df)] = wave_ppg_ecg_list\n",
    "\n",
    "        display(wave_ppg_ecg_df)\n",
    "        SelectData(np.array([ref_bp_wave, est_bp_wave]).T).show_data()\n",
    "        SelectData(ppg_wave_a[:min_len_ppg]).show_data()\n",
    "        SelectData(ref_bp_wave_a[:min_len_ppg]).show_data()\n",
    "        SelectData(ecg_wave).show_data()\n",
    "        SelectData(ref_bp_wave).show_data()\n",
    "\n",
    "    wave_ppg_ecg_df.to_csv(f'wave_ppg_ecg_{len(patient_list)}.csv')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_ppg_ecg_df80 = pd.concat([pd.read_csv('wave_ppg_ecg10.csv'), pd.read_csv('wave_ppg_ecg_70.csv')])\n",
    "# wave_ppg_ecg_df = wave_ppg_ecg_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_ppg_ecg_df80.to_csv('wave_ppg_ecg80.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc_histogram(wave_ppg_ecg_df):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    # Set your color palette\n",
    "    colors = ['#B0C4DE', '#5F9EA0', '#C6868E']\n",
    "\n",
    "    # Specify data\n",
    "    data1 = np.array(wave_ppg_ecg_df['refbp_estbp_cc'])\n",
    "    data2 = np.array(wave_ppg_ecg_df['refbp_ppg_cc'])\n",
    "    data3 = np.array(wave_ppg_ecg_df['refbp_ecg_cc'])\n",
    "\n",
    "    # Create bins and histogram\n",
    "    bins = np.linspace(0, 1, 11)\n",
    "    counts1, _ = np.histogram(abs(data1), bins=bins)\n",
    "    counts2, _ = np.histogram(abs(data2), bins=bins)\n",
    "    counts3, _ = np.histogram(abs(data3), bins=bins)\n",
    "\n",
    "    # Calculate frequencies\n",
    "    freq1 = counts1 / len(data1)\n",
    "    freq2 = counts2 / len(data2)\n",
    "    freq3 = counts3 / len(data3)\n",
    "\n",
    "    barWidth = 0.25\n",
    "    r1 = np.arange(len(freq1))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    r3 = [x + barWidth for x in r2]\n",
    "\n",
    "    plt.bar(r1, freq1, color=colors[0], width=barWidth, edgecolor='grey', label='refBP_estBP')\n",
    "    plt.bar(r2, freq2, color=colors[1], width=barWidth, edgecolor='grey', label='refBP_PPG')\n",
    "    plt.bar(r3, freq3, color=colors[2], width=barWidth, edgecolor='grey', label='refBP_ECG')\n",
    "\n",
    "    # Adding labels\n",
    "    for i in range(len(r1)):\n",
    "        plt.text(x = r1[i] + barWidth/2 - 0.1 , y = freq1[i] + 0.02, s = f\"{counts1[i]}\", size = 10, ha='center')\n",
    "        plt.text(x = r2[i] + barWidth/2 - 0.1 , y = freq2[i] + 0.02, s = f\"{counts2[i]}\", size = 10, ha='center')\n",
    "        plt.text(x = r3[i] + barWidth/2 - 0.1 , y = freq3[i] + 0.02, s = f\"{counts3[i]}\", size = 10, ha='center')\n",
    "\n",
    "    plt.xlabel('Correlation Coefficient')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks([r + barWidth for r in range(len(freq1))], ['0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4', '0.4-0.5', '0.5-0.6', '0.6-0.7', '0.7-0.8', '0.8-0.9', '0.9-1.0'])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
